<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Briefs — Tony Arteaga</title>
  <meta name="description" content="Short takes on AI, tools, and what I'm learning." />
  <link rel="icon" type="image/png" href="/assets/favicon-96x96.png" sizes="96x96" />
  <link rel="icon" type="image/svg+xml" href="/assets/favicon.svg" />
  <link rel="shortcut icon" href="/assets/favicon.ico" />
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png" />
  <link rel="manifest" href="/site.webmanifest" />
  <link rel="canonical" href="https://anthropic.tonyarteaga.com/briefs.html">
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-slate-50 text-slate-900 antialiased">
  <header class="max-w-4xl mx-auto px-6 py-10">
    <nav class="flex justify-between items-center">
      <div>
        <a href="/" class="text-2xl font-semibold hover:underline">Tony Arteaga</a>
        <span class="block mt-1 px-3 py-1 text-sm font-medium bg-gradient-to-r from-amber-100 to-orange-100 text-amber-800 rounded-full border border-amber-200 w-max">Applying for: Manager, Forward Deployed Engineering — or similar</span>
      </div>
      <div class="space-x-2 text-sm">
        <a href="/" class="hover:underline">Home</a>
        <a href="/ai-journey.html" class="hover:underline">AI Journey</a>
        <a href="/about.html" class="hover:underline">About</a>
        <a href="/briefs.html" class="underline font-medium">Briefs</a>
        <a href="/#contact" class="hover:underline">Contact</a>
        <a href="/resume.html" class="inline-block rounded px-3 py-1 bg-slate-900 text-white">Resume</a>
      </div>
    </nav>
  </header>

  <main class="max-w-3xl mx-auto px-6 pb-20">
    <section class="mt-4">
      <h1 class="text-3xl font-bold">Briefs</h1>
      <p class="mt-2 text-slate-600">Short takes on AI, tools, and other relevant business news.</p>
    </section>

    <!-- Brief: Workslop -->
    <article class="mt-12 border-b border-slate-200 pb-10">
      <time class="text-sm text-slate-500">February 19, 2026</time>
      <h2 class="text-xl font-semibold mt-1">AI mandates create "workslop" — fixing it requires system-level change</h2>
      <div class="mt-3 text-slate-700 space-y-3">
        <p>
          HBR introduced a useful term: <em>workslop</em> — the low-quality, AI-generated output that floods inboxes when organizations mandate AI use without thinking through the implications. The pressure is real: boards want leaner teams, execs feel the push to show AI ROI, and the implicit message is "do more with less."
        </p>
        <p>
          The authors argue this isn't a people problem — it's a system problem. Their three-level fix:
        </p>
        <ul class="list-disc list-outside ml-4 space-y-1">
          <li><strong>Culture:</strong> Rebuild trust through actual collaboration — feedback, questions, dialogue. Not just AI outputs.</li>
          <li><strong>Practice:</strong> Create clear norms for when/how to use AI, with review processes that reinforce human judgment rather than offload it.</li>
          <li><strong>Accountability:</strong> Someone needs to own the AI-human integration. The authors suggest "forward deployed AI collaboration architects" who understand both the tech and the people.</li>
        </ul>
        <p>
          <em>That last point caught my attention — it's basically an FDE role focused on making AI actually work inside organizations.</em> The irony they point out: to make AI work at work, we need to get better at being human.
        </p>
      </div>
      <p class="mt-4 text-sm text-slate-500">
        Source: <a href="https://hbr.org/2026/01/why-people-create-ai-workslop-and-how-to-stop-it" class="underline hover:text-slate-700">Harvard Business Review</a> · Niederhoffer, Robichaux & Hancock · Jan 2026
      </p>
    </article>

    <!-- Brief: Hidden AI use -->
    <article class="mt-10 border-b border-slate-200 pb-10">
      <time class="text-sm text-slate-500">February 19, 2026</time>
      <h2 class="text-xl font-semibold mt-1">Employees are hiding their AI productivity gains — it's human nature</h2>
      <div class="mt-3 text-slate-700 space-y-3">
        <p>
          Ethan Mollick (Wharton) shared a striking finding on the Prof G podcast: about 50% of American workers are using AI and reporting 3x productivity gains on tasks where they use it. But here's the catch — many of them aren't telling their employers. They're not using corporate AI tools. They're keeping it quiet.
        </p>
        <p>
          Why? Because if you (and coworkers) prove you're 3x more efficient, you may be part of the next RIF. Often, the 'calculated' move is to pocket the gains and stay under the radar.
        </p>
        <p>
          This is a real problem, and it won't be solved with mandates or monitoring. It requires honesty: leaders need to make the case — credibly — that AI adoption benefits both the company <em>and</em> the employee. That's easier at growing companies ("we're expanding, let's make you more productive and reward you") than at struggling ones where a RIF feels inevitable.
        </p>
        <p>
          <em>The adoption gap isn't a training problem alone, it's a trust problem.</em>
        </p>
      </div>
      <p class="mt-4 text-sm text-slate-500">
        Source: <a href="https://www.profgmedia.com/podcast" class="underline hover:text-slate-700">Prof G Podcast</a> · Ethan Mollick (Wharton) · Feb 12, 2026
      </p>
    </article>

    <!-- Brief: Pro-worker AI -->
    <article class="mt-10 border-b border-slate-200 pb-10">
      <time class="text-sm text-slate-500">February 18, 2026</time>
      <h2 class="text-xl font-semibold mt-1">Pro-worker AI isn't automatic</h2>
      <div class="mt-3 text-slate-700 space-y-3">
        <p>
          MIT's Daron Acemoglu made a point this week that stuck with me: AI that actually helps workers requires deliberate design. It won't happen by default.
        </p>
        <p>
          Three things that resonated: build domain-specific systems aligned with how experts actually work, design for skill development (not just task completion), <strong>and add friction to prevent blind reliance on AI outputs.</strong>
        </p>
        <p>
          This maps to a best practice where you collaborate with AI tools rather than relying on them blindly. The best tools I've worked with don't try to replace judgment — they surface context and let the human decide. The worst ones optimize for "AI did the thing" without asking whether the thing was right.
        </p>
      </div>
      <p class="mt-4 text-sm text-slate-500">
        Source: <a href="https://mitsloan.mit.edu/ideas-made-to-matter/pro-worker-ai-doesnt-just-happen-companies-need-to-act" class="underline hover:text-slate-700">MIT Sloan</a>
      </p>
    </article>

  </main>

  <footer class="border-t">
    <div class="max-w-3xl mx-auto px-6 py-8 text-xs text-slate-500">
      &copy; <span id="y"></span> Tony Arteaga &bull; <a href="/privacy.html" class="underline">Privacy</a>
    </div>
  </footer>
  <script>document.getElementById('y').textContent = new Date().getFullYear()</script>
</body>
</html>
